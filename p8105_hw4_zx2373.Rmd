---
title: "Homework 6"
author: Ziyan Xu
date: 12/01/2022
output: 
  github_document:
    toc: true
---

This is my solution to HW6. 

```{r setup, include = FALSE}
library(tidyverse)
library(modelr)
library(corrplot) 

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d()
scale_fill_discrete = scale_fill_viridis_d()
```

## Problem 3

 - Tidy dataset.

I convert numeric variables ('babysex', 'frace', 'malform', 'mrace') to factor and change the unit of 'bwt' (from grams to pounds) and 'mheight' (from inches to centimeters). There are no NAs in the dataset, but values of 'pnumlbw' and 'pnumgsa' are all zero. It indicates that these variables may have minimal influences to baby birthweight in this case, thus I excluded them. 

```{r message = FALSE}
baby_df = 
  read_csv("./data/birthweight.csv") %>% 
  mutate(
    babysex = factor(case_when(
      babysex == 1 ~ "male", babysex == 2 ~ "female")),
    frace = factor(case_when(
      frace == 1 ~ "White", frace == 2 ~ "Black", 
      frace == 3 ~ "Asian", frace == 4 ~ "Puerto Rican",
      frace == 8 ~ "Other", frace == 9 ~ "Unknown"
      )),
    malform = factor(case_when(
      malform == 0 ~ "absent", malform == 1 ~ "present"
    )),
    mrace = factor(case_when(
      mrace == 1 ~ "White", mrace == 2 ~ "Black",
      mrace == 3 ~ "Asian", mrace == 4 ~ "Puerto Rican",
      mrace == 8 ~ "Other"
      )),
    bwt = bwt * 0.00220462262,
    mheight = mheight * 2.54
    ) %>% 
  drop_na() %>% 
  select(-pnumlbw, -pnumsga) %>% 
  select(bwt, everything())
```

 - Fit a regression model. 

Firstly, fit a model with all predictors and select variables with p-value less than 0.05 in the anova result. 

```{r}
model_all = lm(bwt ~ ., data = baby_df)

anova(model_all) %>% 
  broom::tidy() %>% 
  filter(p.value < 0.05) %>% 
  select(term, p.value) %>% 
  knitr::kable()
```

Then, create a correlation matrix with numeric variables. The plot shows that parity seems to have weaker correlation with bwt than others, thus excluded for baseline variables. What's more, there are error with 'wtgain' when generating regression model, which maybe caused by collinearity ('delwt' = 'wtgain' + 'ppwt').

```{r}
cor(baby_df[,c(3, 4, 5, 6, 8, 11, 14, 15, 17)]) %>% 
  corrplot(method = "circle", type = "upper", diag = FALSE)

model_bwt = lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + ppbmi + smoken, data = baby_df)

model_bwt %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

Make a plot of model residuals against predicted values.

```{r message = FALSE}
baby_df %>% 
  add_residuals(model_bwt) %>% 
  add_predictions(model_bwt) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Relationship between predicted values and residuals", 
       x = "Predicted values", 
       y = "Residuals")
```

The plot shows that residual values are distributed around 0 and form a horizontal (linear) ‘band’ around zero, though there are several outliers.

 - Fit a model using length at birth and gestational age as predictors, and another model using head circumference, length, sex, and all interactions between them.

```{r}
model_len_ga = lm(bwt ~ blength + gaweeks, data = baby_df)

model_len_ga %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)

model_inter = lm(bwt ~ bhead * blength * babysex, data = baby_df)

model_inter %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

 - Compare the above 3 model using cross validation.

```{r}
cv_df =
  crossv_mc(baby_df, 1000) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
    bwt_mod = map(.x = train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + ppbmi + smoken, data = baby_df)),
    len_ga_mod = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = baby_df)),
    inter_mod = map(.x = train, ~lm(bwt ~ bhead * blength * babysex, data = baby_df))) %>% 
  mutate(
    rmse_bwt = map2_dbl(bwt_mod, .y = test, ~rmse(model = .x, data = .y)),
    rmse_len_ga = map2_dbl(len_ga_mod, .y = test, ~rmse(model = .x, data = .y)),
    rmse_inter = map2_dbl(inter_mod, .y = test, ~rmse(model = .x, data = .y)))
```

Make a plot of rmse of 3 models.

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(
    title = "Comparison of three models using cross validtion"
    )
```

In this plot, we can see that model_bwt that involved multiple variables has the lowest rmse and model_len_ga which only contains two main predictors has the highest rmse. The prediction error of model_inter is slightly higher than model_bwt since it manage interactions between 3 main variables. In short, model_bwt fitted better than the other two.
